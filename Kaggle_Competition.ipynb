{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Competition\n",
    "## Javier Palomares\n",
    "\n",
    "### Data Reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import skew\n",
    "from scipy.stats.stats import pearsonr\n",
    "\n",
    "%config InlineBackend.figure_format = 'png' #set 'png' here when working on notebook\n",
    "%matplotlib inline\n",
    "matplotlib.rcParams['figure.figsize'] = (12.0, 6.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./input/train_final.csv')\n",
    "test = pd.read_csv('./input/test_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Y</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>f3</th>\n",
       "      <th>f4</th>\n",
       "      <th>f5</th>\n",
       "      <th>f6</th>\n",
       "      <th>f7</th>\n",
       "      <th>f8</th>\n",
       "      <th>...</th>\n",
       "      <th>f15</th>\n",
       "      <th>f16</th>\n",
       "      <th>f17</th>\n",
       "      <th>f18</th>\n",
       "      <th>f19</th>\n",
       "      <th>f20</th>\n",
       "      <th>f21</th>\n",
       "      <th>f22</th>\n",
       "      <th>f23</th>\n",
       "      <th>f24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>25884</td>\n",
       "      <td>1</td>\n",
       "      <td>33.63</td>\n",
       "      <td>118596</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>118595</td>\n",
       "      <td>125738</td>\n",
       "      <td>...</td>\n",
       "      <td>1945</td>\n",
       "      <td>118450</td>\n",
       "      <td>119184</td>\n",
       "      <td>1</td>\n",
       "      <td>121372</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>34346</td>\n",
       "      <td>1</td>\n",
       "      <td>10.62</td>\n",
       "      <td>118041</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>117902</td>\n",
       "      <td>130913</td>\n",
       "      <td>...</td>\n",
       "      <td>15385</td>\n",
       "      <td>117945</td>\n",
       "      <td>292795</td>\n",
       "      <td>1</td>\n",
       "      <td>259173</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>34923</td>\n",
       "      <td>1</td>\n",
       "      <td>1.77</td>\n",
       "      <td>118327</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>117961</td>\n",
       "      <td>124402</td>\n",
       "      <td>...</td>\n",
       "      <td>7547</td>\n",
       "      <td>118933</td>\n",
       "      <td>290919</td>\n",
       "      <td>1</td>\n",
       "      <td>118784</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>80926</td>\n",
       "      <td>1</td>\n",
       "      <td>30.09</td>\n",
       "      <td>118300</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>117961</td>\n",
       "      <td>301218</td>\n",
       "      <td>...</td>\n",
       "      <td>4933</td>\n",
       "      <td>118458</td>\n",
       "      <td>118331</td>\n",
       "      <td>1</td>\n",
       "      <td>307024</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4674</td>\n",
       "      <td>1</td>\n",
       "      <td>1.77</td>\n",
       "      <td>119921</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>119920</td>\n",
       "      <td>302830</td>\n",
       "      <td>...</td>\n",
       "      <td>13836</td>\n",
       "      <td>142145</td>\n",
       "      <td>4673</td>\n",
       "      <td>1</td>\n",
       "      <td>128230</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>620</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  Y     f1  f2     f3      f4  f5  f6      f7      f8  ...    f15  \\\n",
       "0   1  1  25884   1  33.63  118596   1   0  118595  125738  ...   1945   \n",
       "1   2  1  34346   1  10.62  118041   1   0  117902  130913  ...  15385   \n",
       "2   3  1  34923   1   1.77  118327   1   0  117961  124402  ...   7547   \n",
       "3   4  1  80926   1  30.09  118300   1   0  117961  301218  ...   4933   \n",
       "4   5  1   4674   1   1.77  119921   1   0  119920  302830  ...  13836   \n",
       "\n",
       "      f16     f17  f18     f19  f20  f21  f22  f23  f24  \n",
       "0  118450  119184    1  121372    1    1    1    2    1  \n",
       "1  117945  292795    1  259173    1    1    1    1    1  \n",
       "2  118933  290919    1  118784    1    1    1    1    1  \n",
       "3  118458  118331    1  307024    1    1    1    2    1  \n",
       "4  142145    4673    1  128230    1    1    1  620    1  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16383, 26)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16383, 24)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train= train.loc[:,'f1':'f24']\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.6372e+04, 3.0000e+00, 4.0000e+00, 2.0000e+00, 0.0000e+00,\n",
       "        1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00]),\n",
       " array([1.0000e+00, 1.0085e+03, 2.0160e+03, 3.0235e+03, 4.0310e+03,\n",
       "        5.0385e+03, 6.0460e+03, 7.0535e+03, 8.0610e+03, 9.0685e+03,\n",
       "        1.0076e+04]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(x_train.f12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train.Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  948.,     0.,     0.,     0.,     0.,     0.,     0.,     0.,\n",
       "            0., 15435.]),\n",
       " array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the y variable is binary classification variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train.loc[:,'f1':'f24']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = test.loc[:,'f1':'f24']\n",
    "ids = test.Id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11',\n",
      "       'f12', 'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20', 'f21',\n",
      "       'f22', 'f23', 'f24'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# get the numberical features \n",
    "numeric_feats = x_train.dtypes[x_train.dtypes != \"object\"].index\n",
    "print(numeric_feats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All features are numeric.\n",
    "\n",
    "I'll find skewed features and drop those with a skewness greater than .85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find skewed features\n",
    "skew_to_drop = .85\n",
    "#compute skewness\n",
    "skewedness_factor = x_train[numeric_feats].apply(lambda x: skew(x.dropna())) #compute skewness\n",
    "skewed_feats = skewedness_factor[skewedness_factor > skew_to_drop].index\n",
    "#f1 has a negative value, don't log transform f1\n",
    "skewed_feats = skewed_feats.delete(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the log of skewed features\n",
    "x_train[skewed_feats] = np.log1p(x_train[skewed_feats])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like most of the features are skewed, but it also looks like several of the columns are integer valued"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll look for binary columns and won't apply any preprocessing to those"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_binary_cols(df):\n",
    "    bin_cols = [col for col in df if \n",
    "               df[col].dropna().value_counts().index.isin([0,1]).all()]\n",
    "    return bin_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_cols = get_binary_cols(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(bin_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's no binary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill NA's with the mean of the column\n",
    "x_train = x_train.fillna(x_train.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models\n",
    "I'll first try fitting a logistic regression classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression,LogisticRegressionCV\n",
    "from sklearn import metrics\n",
    "import datetime\n",
    "# function to compute rmse error\n",
    "def rmse(predicted,target):\n",
    "    return np.sqrt(np.mean((predicted-target)**2))\n",
    "# function to compute the root mean squared error of the cross validation\n",
    "def rmse_cv(model,X_train,y):\n",
    "    rmse= np.sqrt(-cross_val_score(model, X_train, y, scoring=\"neg_mean_squared_error\", cv = 10))\n",
    "    return(rmse)\n",
    "def auc_score(y_pred_proba,y):\n",
    "    return metrics.roc_auc_score(y,y_pred_proba)\n",
    "def write_predictions(filename,header,ids,y_pred):\n",
    "    f = open(filename,'w')\n",
    "    numRows = len(ids)\n",
    "    f.write(header)\n",
    "    for i in range(numRows):\n",
    "        idNum = ids[i]\n",
    "        y = y_pred[i]\n",
    "        f.write(\"{},{}\\n\".format(idNum,y))\n",
    "    f.close()\n",
    "def feature_normalize(dataset):\n",
    "    mu = np.mean(dataset,axis=0)\n",
    "    sigma = np.std(dataset,axis=0)\n",
    "    return (dataset - mu)/sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_alphas = 200\n",
    "alphas = np.logspace(-5, 5, n_alphas).tolist()\n",
    "model_logistic = LogisticRegressionCV(Cs=alphas,cv=10,solver='liblinear').fit(x_train,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_cv(model_logistic,x_train,y).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = test.loc[:,'f1':'f24']\n",
    "y_pred_proba = model_logistic.predict_proba(x_test)[:,1]\n",
    "ids = test.Id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5321711163870813\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5321711163870813"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_pred_proba = model_logistic.predict_proba(x_train)[:,1]\n",
    "fpr,tpr, _ = metrics.roc_curve(y,y_train_pred_proba)\n",
    "auc = metrics.auc(fpr,tpr)\n",
    "print(auc)\n",
    "metrics.roc_auc_score(y,y_train_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "write_predictions(\"predictions/prediction\"+datetime.datetime.now().isoformat() + \".csv\",\"Id,Y\\n\",ids,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "vanilla_logistic = LogisticRegression(C=1e-5,solver='lbfgs').fit(x_train,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_vanilla = vanilla_logistic.predict_proba(x_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.93979353 0.94021113 0.95522887 ... 0.94096549 0.93982833 0.93949173]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred_vanilla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_predictions(\"predictions/pure_vanilla_\"+datetime.datetime.now().isoformat()+\".csv\",\"Id,Y\\n\",ids,y_pred_vanilla)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = model_logistic.C_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1e-05"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vanilla_logistic.C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now trying XGBoost classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import loadtxt\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train.loc[:,'f1':'f24']\n",
    "y = train.Y\n",
    "x_test = test.loc[:,'f1':'f24']\n",
    "ids = test.Id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* XGboost classifier with no normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = XGBClassifier()\n",
    "model.fit(x_train,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_xgboost = model.predict_proba(x_test)[:,1]\n",
    "y_train_xgboost = model.predict_proba(x_train)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9057251451916913"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xg_boost_auc_score = auc_score(y_pred_proba=y_train_xgboost,y=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xgboost scored 0.85731"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time, do some preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train.loc[:,'f1':'f24']\n",
    "y = train.Y\n",
    "x_test = test.loc[:,'f1':'f24']\n",
    "ids = test.Id\n",
    "# get the numberical features \n",
    "numeric_feats = x_train.dtypes[x_train.dtypes != \"object\"].index\n",
    "# find skewed features\n",
    "skew_to_drop = .75\n",
    "#compute skewness\n",
    "skewedness_factor = x_train[numeric_feats].apply(lambda x: skew(x.dropna())) #compute skewness\n",
    "skewed_feats = skewedness_factor[skewedness_factor > skew_to_drop].index\n",
    "#f1 has a negative value, don't log transform f1\n",
    "skewed_feats = skewed_feats.delete(0)\n",
    "# take the log of skewed features\n",
    "x_train[skewed_feats] = np.log1p(x_train[skewed_feats])\n",
    "x_test[skewed_feats] = np.log1p(x_train[skewed_feats])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_xg_boost_norm = XGBClassifier()\n",
    "model_xg_boost_norm.fit(x_train,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_xgboost_norm = model_xg_boost_norm.predict_proba(x_test)[:,1]\n",
    "y_train_xgboost_norm = model_xg_boost_norm.predict_proba(x_train)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9057251451916913"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc_score(y_pred_proba =y_train_xgboost_norm,y=y )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_predictions(\"predictions/xgboost_normalized\"+datetime.datetime.now().isoformat()+\".csv\",\"Id,Y\\n\",ids,y_test_xgboost_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xgboost + normalization scored 0.82317, not an improvement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, try dropping non important features, also optimizing over a bigger range of values for xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now trying tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 16383\n"
     ]
    }
   ],
   "source": [
    "feature_count = x_train.shape[1]\n",
    "label_count = y.shape[0]\n",
    "print(feature_count, label_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jpalomares/.local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# inputs\n",
    "training_epochs = 3000\n",
    "learning_rate = 0.01\n",
    "hidden_layers = feature_count - 1\n",
    "cost_history = np.empty(shape=[1],dtype=float)\n",
    "\n",
    "X = tf.placeholder(tf.float32,[None,feature_count])\n",
    "Y = tf.placeholder(tf.float32,[None,label_count])\n",
    "is_training=tf.Variable(True,dtype=tf.bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From <ipython-input-47-14b7e5110d3d>:4: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n"
     ]
    }
   ],
   "source": [
    "# models\n",
    "\n",
    "initializer = tf.contrib.layers.xavier_initializer()\n",
    "h0 = tf.layers.dense(X, hidden_layers, activation=tf.nn.relu, kernel_initializer=initializer)\n",
    "# h0 = tf.nn.dropout(h0, 0.95)\n",
    "h1 = tf.layers.dense(h0, label_count, activation=None)\n",
    "\n",
    "cross_entropy = tf.nn.sigmoid_cross_entropy_with_logits(labels=Y, logits=h1)\n",
    "cost = tf.reduce_mean(cross_entropy)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Keras classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline model\n",
    "def create_baseline():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(24, input_dim=24, kernel_initializer='normal', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = KerasClassifier(build_fn=create_baseline, epochs=100, batch_size=5, verbose=0)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/jpalomares/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-079c762c44f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkfold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Results: %.2f%% (%.2f%%)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    400\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m                                 \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m                                 error_score=error_score)\n\u001b[0m\u001b[1;32m    403\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    238\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m             error_score=error_score)\n\u001b[0;32m--> 240\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    918\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sample_weight'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKerasClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0mfit_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results = cross_val_score(estimator, x_train, y, cv=kfold)\n",
    "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd7cb0114a8>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.fit(x_train,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_pred = estimator.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_pred = keras_pred[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(keras_pred)\n",
    "# predicts everything as one. Need to balance number of samples. do that and then standardize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
